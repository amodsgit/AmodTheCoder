{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amodsgit/AmodTheCoder/blob/main/Falcon7b_QLoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tuning the Falcon7-b LLM for Specialized Mental Health Therapy Applications using QLoRA**\n",
        "\n",
        "A Project by Amod\n",
        "\n",
        "Get comparable performance to full finetuning by adapting LLMs to downstream tasks using consumer hardware"
      ],
      "metadata": {
        "id": "1j8nhuRaZBjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of newer labraries used within the project:\n",
        "\n",
        "Bitsandbytes: is a lightweight wrapper around CUDA custom functions, in particular 8-bit optimizers and quantization functions.\n",
        "\n",
        "ðŸ¤— (Hugging Face) Accelerate: was created for PyTorch users who like to write the training loop of PyTorch models but are reluctant to write and maintain the boilerplate code needed to use multi-GPUs/TPU/fp16.\n",
        "\n",
        "\n",
        "> ðŸ¤— Accelerate abstracts exactly and only the boilerplate code related to multi-GPUs/TPU/fp16 and leaves the rest of your code unchanged.\n",
        "\n",
        "Einops : Enables easy tensor operations\n",
        "\n",
        "Loralib: PyTorch implementation of low-rank adaptation (LoRA), a parameter-efficient approach to adapt a large pre-trained deep learning model which obtains performance on-par with full model fine-tuning\n",
        "\n",
        "XFormers (optional): A collection of composable Transformer building blocks."
      ],
      "metadata": {
        "id": "RMaW3ud6xWng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVEwK8exTOmG"
      },
      "outputs": [],
      "source": [
        "!pip install -qU bitsandbytes transformers datasets accelerate loralib einops xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF0gYxCezHpC"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/peft.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgjXtugbYpmE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import bitsandbytes as bnb\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from datasets import load_dataset\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    PeftConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        ")\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZzmS9kQZcds"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "please add an explanation\n",
        "\"\"\"\n",
        "\n",
        "model_id = \"tiiuae/falcon-7b\" # we are using falcon 7b as our base model\n",
        "\n",
        "# bitsandbytes configuration for loading the model in NF4\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    load_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model =AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOD9rLaWaTjG"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IETKOBiRfLBM"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model) # initialize model for QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-fkzAk9fM4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "074ec181-064d-4b82-e80e-8219ae2db787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 4718592 || all params: 3613463424 || trainable%: 0.13058363808693696\n"
          ]
        }
      ],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Meaning of the parameters in loraconfig (Include these in the code explanation) :\n",
        "r: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters.\n",
        "target_modules: The modules (for example, attention blocks) to apply the LoRA update matrices.\n",
        "lora_alpha: LoRA scaling factor\n",
        "bias: Specifies if the bias parameters should be trained. Can be 'none', 'all' or 'lora_only'\n",
        "lora_dropout: dropout probability of the LoRA layers\n",
        "\"\"\"\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatting each Datapoint (Question answer pair of the dataset) to be loaded into training\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JDV7GpSeVJmT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pisCY6iDfX2N"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Fuctions to Format and tokenize each Datapoint (Question answer pair of the dataset) to be loaded into training\n",
        " \"\"\"\n",
        "\n",
        "def generate_prompt(data_point):\n",
        "  return f\"\"\"\n",
        "<Human>: {data_point[\"Context\"]}\n",
        "<AI>: {data_point[\"Response\"]}\n",
        "  \"\"\".strip()\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "  full_prompt = generate_prompt(data_point)\n",
        "  tokenized_full_prompt = tokenizer(full_prompt, padding=True, truncation=True)\n",
        "  return tokenized_full_prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Dataset"
      ],
      "metadata": {
        "id": "Bqgyf4CrVSwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V_J1XY5fiit"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset_name = 'Amod/mental_health_counseling_conversations'  # a custom dataset of 3512 high quality therapy conversations\n",
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling the Dataset"
      ],
      "metadata": {
        "id": "gu7rQwDOVV7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9TZWSXifl7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e281be4-ca51-49f5-f182-855e7e3df492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Context': \"When I'm around people, I sometimes think someone has made a comment to me or asked me to do something. I will be focusing on something else and then randomly think I hear something about me. I never know if it was actually said.\",\n",
              " 'Response': \"It sounds like you are having difficulty knowing if people are saying things to you, or if you only thought someone was talking to you, and this is anxiety producing. It's understandable that it could be confusing and/or a bit scary to be unsure if people are speaking to you or not. It's hard to say exactly what is going on from just this description, but if you can work with a competent therapist, you may be able to get more insight into what is happening, get clarity about your social interactions, and develop some ways to deal with the anxiety.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset[400]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalizing and Mapping the dataset for finetuning"
      ],
      "metadata": {
        "id": "dGzko4IYVZZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_4-L6RtukRM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "078640de821c455e8b7c0f1f14278065",
            "3251097422b44e578276313006fb20dd",
            "6602cd94378f40c2a2ee3ed9e6c1b233",
            "a8aa4218b0b143908ad2cadeb1cb12e5",
            "f89ef9207d1249229c3962ccacf85904",
            "1825e72ff6824ef5a9e8f8f5d01137bc",
            "01fc303638964c769c3700ccad90afcc",
            "10f9c59184c24274a18f5d0400fa0e92",
            "45982b1a29aa4967aca40b26e6f0e129",
            "fe8482b2171547439b758a804d02c726",
            "af626c57e25244e386fdc70baf5211dd"
          ]
        },
        "outputId": "64e1dbd5-1f7a-4a41-d8eb-1e2e007a1946"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3512 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "078640de821c455e8b7c0f1f14278065"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"plese add an explanation for this code: \"\"\"\n",
        "dataset = dataset.shuffle().map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_zzdEFuuw7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e239ba-5a19-4f86-98e8-2a642db65b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3512, 5)\n"
          ]
        }
      ],
      "source": [
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP0hBNrFxzp8"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"experiments\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Explain the transformers Trainer. explain each traing argument\n",
        "\"\"\"\n",
        "\n",
        "training_args = transformers.TrainingArguments(\n",
        "    auto_find_batch_size=True,\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=2e-4,\n",
        "    bf16=True,\n",
        "    save_total_limit=4,\n",
        "    logging_steps=10,\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    save_strategy='epoch',\n",
        ")\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    args=training_args,\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()    # Commence training\n"
      ],
      "metadata": {
        "id": "T6fwyN8pNBhl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "078640de821c455e8b7c0f1f14278065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3251097422b44e578276313006fb20dd",
              "IPY_MODEL_6602cd94378f40c2a2ee3ed9e6c1b233",
              "IPY_MODEL_a8aa4218b0b143908ad2cadeb1cb12e5"
            ],
            "layout": "IPY_MODEL_f89ef9207d1249229c3962ccacf85904"
          }
        },
        "3251097422b44e578276313006fb20dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1825e72ff6824ef5a9e8f8f5d01137bc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_01fc303638964c769c3700ccad90afcc",
            "value": "Map: 100%"
          }
        },
        "6602cd94378f40c2a2ee3ed9e6c1b233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10f9c59184c24274a18f5d0400fa0e92",
            "max": 3512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45982b1a29aa4967aca40b26e6f0e129",
            "value": 3512
          }
        },
        "a8aa4218b0b143908ad2cadeb1cb12e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8482b2171547439b758a804d02c726",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_af626c57e25244e386fdc70baf5211dd",
            "value": " 3512/3512 [00:06&lt;00:00, 546.20 examples/s]"
          }
        },
        "f89ef9207d1249229c3962ccacf85904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1825e72ff6824ef5a9e8f8f5d01137bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fc303638964c769c3700ccad90afcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10f9c59184c24274a18f5d0400fa0e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45982b1a29aa4967aca40b26e6f0e129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe8482b2171547439b758a804d02c726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af626c57e25244e386fdc70baf5211dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}